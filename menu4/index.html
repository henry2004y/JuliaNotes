<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/JuliaNotes/libs/highlight/github.min.css"> <link rel=stylesheet  href="/JuliaNotes/css/franklin.css"> <link rel=stylesheet  href="/JuliaNotes/css/pure.css"> <link rel=stylesheet  href="/JuliaNotes/css/side-menu.css"> <style> .franklin-content{padding-left:10%;} @media (min-width: 940px) { .franklin-content {width: 640px; margin-left: 0px; padding-left: 80px;} .header {width: 700px;} } </style> <link rel=icon  href="/JuliaNotes/assets/favicon.png"> <title>Parallel</title> <div id=layout > <a href="#menu" id=menuLink  class=menu-link ><span></span></a> <div id=menu > <div class=pure-menu > <a class=pure-menu-heading  href="#">Pure-SM</a> <ul class=pure-menu-list > <li class="pure-menu-item "><a href="/JuliaNotes/" class=pure-menu-link >Home</a> <li class="pure-menu-item "><a href="/JuliaNotes/menu1/" class=pure-menu-link >Questions</a> <li class="pure-menu-item "><a href="/JuliaNotes/menu2/" class=pure-menu-link >Types</a> <li class="pure-menu-item "><a href="/JuliaNotes/menu3/" class=pure-menu-link >Meta</a> <li class="pure-menu-item pure-menu-selected"><a href="/JuliaNotes/menu4/" class=pure-menu-link >Parallel</a> <li class="pure-menu-item "><a href="/JuliaNotes/menu5/" class=pure-menu-link >Interoperability</a> <li class="pure-menu-item "><a href="/JuliaNotes/menu6/" class=pure-menu-link >Issues and Tricks</a> <li class="pure-menu-item "><a href="/JuliaNotes/menu7/" class=pure-menu-link >Perception</a> </ul> </div> </div> <div id=main > <div class=header > <h1>Parallel</h1> <h2>Notes taken during the learning process</h2> </div> <div class=franklin-content ><h1 id=parallel_computing ><a href="#parallel_computing" class=header-anchor >Parallel Computing</a></h1> <p>Julia introduced to me several different patterns of parallel execution. I learned from failures and unexpected performance. For example, the built-in one-sided parallel communication is very confusing and hard to use for me. I need more time and exprience.</p> <p>Mechanisms for distributed computing are built into the Julia language. But to fully take advantage of it, we need much more than the built-in support, and often we need extra packages from the community.</p> <h2 id=coroutines ><a href="#coroutines" class=header-anchor >Coroutines</a></h2> <h2 id=multiple_processes ><a href="#multiple_processes" class=header-anchor >Multiple processes</a></h2> <ul> <li><p>Specify the number of required worker processes using the <code>-p</code> option on Julia startup.</p> <li><p>Check the number of workers in Julia by using the <code>nworkers&#40;&#41;</code> function from the Distributed package.</p> <li><p>If you want to execute some script on every worker on startup, you can do it using the <code>-L</code> option. When the <code>-L</code> option is passed, then Julia stays in command line after executing the script &#40;as opposed to running a script normally, where we have to pass the <code>-i</code> option to remain in REPL&#41;.</p> </ul> <p>It is important to understand that when you start N workers, where N is greater than 1, then Julia will spin up N&#43;1 processes. <code>-p &#123;N|auto&#125;</code>, tells Julia to spin up N <em>additional</em> worker processes on startup.</p> <p>You can also add processes after Julia has started using the <code>addprocs</code> function. <code>addprocs</code> does not execute the script that was specified by the <code>-L</code> switch on Julia startup.</p> <p>Check the ID numbers of the master and worker processes:</p> <pre><code class="julia-repl hljs"><span class=hljs-meta >julia&gt;</span><span class=language-julia > <span class=hljs-keyword >using</span> Distributed
</span>
<span class=hljs-meta >julia&gt;</span><span class=language-julia > addprocs(<span class=hljs-number >1</span>)
</span>
<span class=hljs-meta >julia&gt;</span><span class=language-julia > Distributed.myid()
</span>
1

<span class=hljs-meta >julia&gt;</span><span class=language-julia > workers()
</span>
1-element Array{Int64,1}:
 2
<span class=hljs-meta >julia&gt;</span><span class=language-julia > res = <span class=hljs-meta >@spawnat</span> <span class=hljs-number >2</span> myid()
</span>
<span class=hljs-meta >julia&gt;</span><span class=language-julia > fetch(res)</span></code></pre> <p>Simple function:</p> <pre><code class="julia hljs">remote_f = <span class=hljs-keyword >function</span>(s::<span class=hljs-built_in >Int</span>=<span class=hljs-number >3</span>)
    println(<span class=hljs-string >&quot;Worker <span class=hljs-subst >$(myid()</span>) will sleep for <span class=hljs-variable >$s</span> seconds&quot;</span>)
    sleep(s)
    val=rand(<span class=hljs-number >1</span>:<span class=hljs-number >1000</span>)
    println(<span class=hljs-string >&quot;Completed worker <span class=hljs-subst >$(myid()</span>) - return <span class=hljs-variable >$val</span>&quot;</span>)
    <span class=hljs-keyword >return</span> val
<span class=hljs-keyword >end</span></code></pre> <p>Now, let&#39;s test the function:</p> <pre><code class="julia-repl hljs"><span class=hljs-meta >julia&gt;</span><span class=language-julia > <span class=hljs-meta >@fetchfrom</span> <span class=hljs-number >2</span> remote_f(<span class=hljs-number >4</span>)
</span>
      From worker 2:    Worker 2 will sleep for 4 seconds
      From worker 2:    Completed worker 2 - return 466
466</code></pre> <p>Now, let&#39;s define a function that runs a remote process, waits a given time, and collects the results:</p> <pre><code class="julia hljs"><span class=hljs-keyword >function</span> run_timeout(timeout::<span class=hljs-built_in >Int</span>, f::<span class=hljs-built_in >Function</span>, params...)    
    wid = addprocs(<span class=hljs-number >1</span>)[<span class=hljs-number >1</span>]
    result = RemoteChannel(()-&gt;<span class=hljs-built_in >Channel</span>{<span class=hljs-built_in >Tuple</span>}(<span class=hljs-number >1</span>));
    <span class=hljs-meta >@spawnat</span> wid put!(result, (f(params...), myid()))
    res = <span class=hljs-literal >nothing</span>    
    time_elapsed = <span class=hljs-number >0.0</span>
    <span class=hljs-keyword >while</span> time_elapsed &lt; timeout &amp;&amp; !isready(result)
        sleep(<span class=hljs-number >0.25</span>)
        time_elapsed += <span class=hljs-number >0.25</span>
    <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >if</span> !isready(result)
        println(<span class=hljs-string >&quot;Not completed! Computation at <span class=hljs-variable >$wid</span> will be 
        terminated!&quot;</span>)        
    <span class=hljs-keyword >else</span>
        res = take!(result)
    <span class=hljs-keyword >end</span>
    rmprocs(wid);
    <span class=hljs-keyword >return</span> res
<span class=hljs-keyword >end</span></code></pre> <p>Now, let&#39;s use the <code>run_timeout</code> function to run the <code>remote_f</code> function remotely; we start by assigning an amount of time that a job can complete:</p> <pre><code class="julia-repl hljs"><span class=hljs-meta >julia&gt;</span><span class=language-julia > run_timeout(<span class=hljs-number >3</span>, remote_f, <span class=hljs-number >2</span>)
</span>
      From worker 3:    Worker 3 will sleep for 2 seconds
      From worker 3:    Completed worker 3 - return 335
(335, 3)</code></pre> <p>Then, run a job that lasts longer than an actual computation:</p> <pre><code class="julia-repl hljs"><span class=hljs-meta >julia&gt;</span><span class=language-julia > run_timeout(<span class=hljs-number >3</span>, remote_f, <span class=hljs-number >10</span>)
</span>
      From worker 4:    Worker 4 will sleep for 10 seconds
Not completed! Computation at 4 will be terminated!</code></pre> <p>We can see that this job has spawned a new process with an ID equal to 4, and this process terminated after three seconds &#40;when the timeout was reached&#41;. </p> <p>Functions must be defined on every processor that is being called:</p> <pre><code class="julia-repl hljs"><span class=hljs-meta >julia&gt;</span><span class=language-julia > <span class=hljs-keyword >using</span> Distributed
</span>

<span class=hljs-meta >julia&gt;</span><span class=language-julia > <span class=hljs-meta >@everywhere</span> <span class=hljs-keyword >function</span> myF2(); println(<span class=hljs-string >&quot;myF2 &quot;</span>, myid()); <span class=hljs-keyword >end</span>;
</span>
​
<span class=hljs-meta >julia&gt;</span><span class=language-julia > <span class=hljs-meta >@spawnat</span> workers()[<span class=hljs-keyword >end</span>] myF2();
</span>
​
       From worker 3:    myF2 3</code></pre> <p>However, in the case of anonymous functions, they can be passed as parameters to the preceding macros. Still, if a function uses a method not defined on a remote process then it will fail:</p> <pre><code class="julia-repl hljs"><span class=hljs-meta >julia&gt;</span><span class=language-julia > hello() = println(<span class=hljs-string >&quot;hello&quot;</span>);
</span>
​
<span class=hljs-meta >julia&gt;</span><span class=language-julia > <span class=hljs-meta >@fetchfrom</span> <span class=hljs-number >2</span> hello()
</span>
ERROR: On worker 2:
UndefVarError: #hello not defined
​
<span class=hljs-meta >julia&gt;</span><span class=language-julia > f_lambda = () -&gt; hello();
</span>
​
<span class=hljs-meta >julia&gt;</span><span class=language-julia > f_lambda()
</span>
hello
​
<span class=hljs-meta >julia&gt;</span><span class=language-julia > <span class=hljs-meta >@fetchfrom</span> <span class=hljs-number >2</span> f_lambda()
</span>
ERROR: On worker 2:
UndefVarError: #hello not defined</code></pre> <p>The solution is, again, <code>@everywhere</code>.</p> <h2 id=multiple_threads ><a href="#multiple_threads" class=header-anchor >Multiple threads</a></h2> <p>Julia can be run in a multithreaded mode. This has gone through many improvements in recent versions, and may be subject to change in the future. This mode is achieved via the <code>JULIA_NUM_THREADS</code> system environment variable, or the <code>-t</code> option when opening Julia. One should perform the following steps:</p> <ul> <li><p>To start Julia with the number of threads equal to the number of cores in your machine, you have to set the environment variable <code>JULIA_NUM_THREADS</code> first; otherwise start Julia with <code>-p&#61;N</code> where N is the number of threads.</p> <li><p>Check how many threads Julia is using with the <code>Threads.nthreads&#40;&#41;</code> function.</p> </ul> <p>As you have seen, in order to start Julia with multiple threads, you have to set the environment variable <code>JULIA_NUM_THREADS</code>. It is used by Julia to determine how many threads it should use. This value –- in order to have any effect –- must be set before Julia is started. This means that you can access it via the <code>ENV&#91;&quot;JULIA_NUM_THREADS&quot;&#93;</code> option but changing it when Julia is running will not add or remove threads.</p> <h2 id=distributed_computing ><a href="#distributed_computing" class=header-anchor >Distributed computing</a></h2> <p>Julia provides built-in language functionality to run a program across many processes that can run locally, across a distributed network, or in a computational cluster.</p> <p>A typical scenario for distributed computing is running a parameter sweep over a significantly large set of computations. In this recipe, we will show how to create a distributed cluster that performs a parameter sweep over a numerical simulation model.</p> <p>We explain how to use the <code>--machine-file</code> Julia options to run Julia workers across many nodes. However, the computational example can also be run on a single machine using the multiprocessing mode &#40;for example, in Julia launched with the julia <code>-p 4</code> command&#41;.</p> <p>In order to build a distributed cluster, we need to configure passwordless SSH. Julia uses SSH connections to spawn workers on remote nodes. For passwordless SSH, we will configure key-based authentication. In order for passwordless SSH to work, the master node needs to have the private key, while each slave node needs to have the public key in the <code>~/.ssh/authorized_users</code> file.</p> <p>We assume that Linux Ubuntu 18.04.1 LTS is used and the username for the computations is ubuntu. We start by creating the key. You will find the command and a sample output, as follows:</p> <pre><code class="julia hljs">ssh-keygen -P <span class=hljs-string >&quot;&quot;</span> -t rsa -f ~/.ssh/cluster</code></pre>
<p>The next step is to edit the <code>~/.ssh/config</code> file. Ensure that the following lines are present:</p>
<pre><code class="plaintext hljs">User ubuntu
PubKeyAuthentication yes
StrictHostKeyChecking no
IdentityFile ~/.ssh/cluster</code></pre>
<p>Now, we need to add the contents of the public key to the <code>~/.ssh/authorized_keys</code> file. Please note that the contents of <code>~/.ssh/cluster.pub</code> should be copied to <code>~/.ssh/authorized_keys</code> on every node in the cluster:</p>
<p>Now, we can test our configuration on a local machine:</p>
<pre><code class="julia hljs">$ ssh ubuntu<span class=hljs-meta >@localhost</span></code></pre>
<p>Distributed multiprocessing in Julia is achieved using the <code>--machine-file</code> launch option of the julia command. The functionality is similar to the <code>-p</code> option but much more powerful since you can distribute Julia over any cluster size. Sample <code>machinefile.txt</code> content is presented in the following code snippet. The first number in each line provides the number of worker processes that should be started on the remote host. It is followed by an asterisk <code>*</code> character and the username on the remote host. In a production environment, you would provide IP addresses of the remote host rather than 127.0.0.1:</p>
<pre><code class="plaintext hljs">2*ubuntu@127.0.0.1
1*ubuntu@127.0.0.1
1*ubuntu@127.0.0.1</code></pre>
<p>The preceding options will allow you to use Julia&#39;s distributed cluster mechanism on just a single local machine. We recommend that you also try adding the IP addresses of the remote machines to the preceding file.</p>
<p>Once you have the <code>machinefile.txt</code> file ready, you can tell Julia to load it by running the following command:</p>
<pre><code class="julia hljs">$ julia --machine-file machinefile.txt</code></pre>
<p>This will launch the Julia master process and a number of Julia slave processes, according to the definitions given in the <code>machinefile.txt</code> file.</p>
<p>If you use a <em>High Performance Computing &#40;HPC&#41;</em> system such as Cray, the passwordless SSH mechanism might not be available. However, such systems usually contain some form of cluster job management software, such as <code>SLURM</code>, <code>SGE</code>, or <code>PBS</code>. These job managers can be used from within Julia via the <a href="https://github.com/JuliaParallel/ClusterManagers.jl">ClusterManagers.jl</a> package.</p>
<h2 id=distributedarray ><a href="#distributedarray" class=header-anchor >DistributedArray</a></h2>
<p>There are supports to the SPMD through the package DistributedArray. However, currently it is not so easy to learn, and the performance is bad.</p>
<ol>
<li><p>To set the values of DArray, you need to first make them local. A typical way of doing this is by saying <code>mylp &#61; d_in&#91;:L&#93;</code>, and them work on the local reference <code>mylp</code>.</p>

<li><p>The initialization of DArray requires special attention to the format. I opt for the do-block syntax, but the syntax itself needs some time to understand.</p>

</ol>
<h2 id=questions ><a href="#questions" class=header-anchor >Questions</a></h2>
<ol>
<li><p>I am still not sure about using MPI in Julia: since I can only do this in command line, does it mean that every time the code needs to be recompiled?</p>

</ol>
<p>The answer is yes. This question reflects my misunderstanding of the underlying workflow. Every Julia function and type is compiled the first time it is executed. This has nothing to do with MPI, which is a standard for inter-process communication. MPI is implemented in C, so the MPI.jl package is basically calling the C library for sending/receiving data from other processors.</p>
<p>Checkout more about CPU parallel computing in Julia in <a href="https://github.com/henry2004y/ParallelJulia">ParallelJulia</a>. </p>
<div class=page-foot >
  <div class=copyright >
    &copy; Hongyang Zhou. Last modified: June 06, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
      </div> 
  </div> 
  <script src="/JuliaNotes/libs/pure/ui.min.js"></script>